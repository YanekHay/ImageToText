{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f97d190-505c-4a44-be3d-bb44cb1cd6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2646338-33bf-42ac-b1ba-f1e09b648d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_root = Path(\"../../Data/Words/charts1_fine_tuned/\")\n",
    "# dest_root = Path(\"../../TRAIN_DATA/Words_fine_tuned\")\n",
    "\n",
    "data_root = Path(\"../../Data/Letters_2\")\n",
    "dest_root = Path(\"../../TRAIN_DATA/Letters_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61fa4110-248a-4ff7-bb62-b4611e3cdea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('../../Data/Letters_2')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subfolders = list(data_root.glob(\"./charts*\"))\n",
    "if len(subfolders)==0 :\n",
    "    subfolders = [data_root]\n",
    "\n",
    "subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "874312b1-735e-499a-9747-0703503d062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path:Path|str):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "def xyxy2xywh(xyxy:np.ndarray, img_width, img_height):\n",
    "    if xyxy.ndim==1:\n",
    "        xyxy = xyxy[None]\n",
    "    w = (xyxy[:, 2] - xyxy[:, 0]) / img_width\n",
    "    h = (xyxy[:, 3] - xyxy[:, 1]) / img_height\n",
    "    \n",
    "    x = xyxy[:, 0]/img_width + w/2\n",
    "    y = xyxy[:, 1]/img_height + h/2\n",
    "    \n",
    "    return np.stack((x, y, w, h)).T\n",
    "\n",
    "\n",
    "\n",
    "def get_segmentation_from_box(box):\n",
    "    x0,y0,w,h = box\n",
    "    t = y0\n",
    "    b = y0 + h\n",
    "    l = x0\n",
    "    r = x0 + w\n",
    "\n",
    "    # [x0,y0, x1,y1, x2,y2, x3,y3]\n",
    "    return [l,t, r,t, r,b, l,b]\n",
    "\n",
    "def convert_coco_to_yolo(image_paths, annotation_path):\n",
    "    with open(annotation_path, \"r\") as f:\n",
    "        json_labels = json.load(f)\n",
    "    data = {}\n",
    "    \n",
    "    for i, annot in enumerate(json_labels[\"annotations\"]):\n",
    "        img_id = annot[\"image_id\"]\n",
    "\n",
    "        json_image =  json_labels[\"images\"][img_id-1] ## -1 is because the indexing starts from 1\n",
    "\n",
    "        img_width = json_image[\"width\"]\n",
    "        img_height = json_image[\"height\"]\n",
    "\n",
    "        file_name = Path(json_image[\"file_name\"])\n",
    "\n",
    "        category = annot[\"category_id\"] - 1\n",
    "        if len(annot[\"segmentation\"])==0:\n",
    "            segments = np.array(get_segmentation_from_box(annot[\"bbox\"]), dtype=float)\n",
    "        else:\n",
    "            segments = np.array(annot[\"segmentation\"][0], dtype=float)\n",
    "        bbox = np.array(annot[\"bbox\"], dtype=float)\n",
    "        \n",
    "        # Rescaling\n",
    "        segments[::2] /= img_width # Dividing x \n",
    "        segments[1::2] /= img_height # Dividing y \n",
    "        bbox = xyxy2xywh(bbox, img_width, img_height)[0] # Rescale and Convert to xywh\n",
    "        segment_text = np.array2string(segments)[1:-1].replace('\\n', '') + \"\\n\"\n",
    "        label_string = f\"{category} {segment_text}\"\n",
    "\n",
    "        if img_id not in data.keys():\n",
    "            data[img_id] = {}\n",
    "            data[img_id][\"segments\"] = []\n",
    "\n",
    "        data[img_id][\"filename\"] = file_name\n",
    "        data[img_id][\"segments\"].append(label_string)        \n",
    "    \n",
    "    return data\n",
    "\n",
    "def save_data(img_ids, data, dest_root, image_root, split=\"train\"):  \n",
    "    dst = Path(dest_root/split)\n",
    "    \n",
    "    for p in [dst, dst/\"labels\", dst/\"images\"]:\n",
    "        create_dir(p)\n",
    "    for img_id in img_ids:\n",
    "        filename = data[img_id][\"filename\"]\n",
    "        segments = data[img_id][\"segments\"]\n",
    "        with open(dst/\"labels\"/(filename.stem+\".txt\"), \"w\") as f:\n",
    "            f.writelines(segments)\n",
    "\n",
    "        shutil.copy(image_root/(filename.stem + filename.suffix), dst/\"images/\")\n",
    "\n",
    "def convert_save(subfolders, dest_root, train_data_amount=0.8):\n",
    "    for subfolder in tqdm(subfolders):\n",
    "        image_paths = list(subfolder.glob(\"images/*\"))\n",
    "        annotation_path = list(subfolder.glob(\"annotations/*.json\"))[0]\n",
    "\n",
    "        print(annotation_path)\n",
    "        data = convert_coco_to_yolo(image_paths, annotation_path)\n",
    "        image_ids = list(data.keys())\n",
    "        np.random.shuffle(image_ids)\n",
    "        split_index = int(len(image_ids)*train_data_amount)\n",
    "\n",
    "\n",
    "        train_ids = image_ids[:split_index]\n",
    "        val_ids = image_ids[split_index:]\n",
    "\n",
    "        save_data(train_ids, data, dest_root, subfolder/\"images\", split=\"train\")\n",
    "        save_data(val_ids, data, dest_root, subfolder/\"images\", split=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e87b4032-56ad-4635-a762-8249b2b42332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93690464f0a540c1bd91389f3d55dff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\..\\Data\\Letters_2\\annotations\\instances_default.json\n"
     ]
    }
   ],
   "source": [
    "convert_save(subfolders, dest_root, train_data_amount=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8bbc5e-2674-4949-b113-63202877f3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
